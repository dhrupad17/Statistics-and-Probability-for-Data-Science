# Bayes' Theorem 

## What is Bayes' Theorem?

- **Bayes' Theorem** is a fundamental concept in probability theory and statistics that describes how to update the probability of a hypothesis based on new evidence.
- It provides a mathematical framework for reasoning about uncertainty and revising beliefs in light of new data.

## The Formula

Bayes' Theorem is expressed as:

![image](https://github.com/user-attachments/assets/4c6774e7-bd52-4d00-aaee-959f501680c7)


## Interpretation of Bayes' Theorem

- **Prior Probability (\( P(H) \))**: Represents our initial belief about the hypothesis before seeing the evidence.
- **Likelihood (\( P(E \ H) \))**: Measures how likely the observed evidence is if the hypothesis is true.
- **Posterior Probability (\( P(H \ E) \))**: Represents our updated belief about the hypothesis after taking the evidence into account.
- **Evidence (\( P(E) \))**: Ensures that the probabilities are properly normalized.

## Example of Bayes' Theorem

![image](https://github.com/user-attachments/assets/9e509e52-0589-4af3-951c-dc6802e26f0f)

![image](https://github.com/user-attachments/assets/bc08809d-8763-4421-b523-ebbae02e3159)



## Applications of Bayes' Theorem

- **Medical Diagnosis:** Updating the probability of a disease based on test results.
- **Spam Filtering:** Calculating the probability that an email is spam based on its contents.
- **Machine Learning:** Used in algorithms like Naive Bayes classifiers.
- **Legal Reasoning:** Updating the likelihood of a hypothesis (e.g., guilt or innocence) based on new evidence.


